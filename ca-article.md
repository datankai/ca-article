# El Próximo Cambridge Analytica
El caso de CA ha estado en boca de todos durante los últimos días, pero para nosotros en [The Data Pub](https://twitter.com/thedatapub), la comunidad de Ciencia de Datos más grande de México, han estado en nuestra mira desde ese [famoso artículo de Vice](https://motherboard.vice.com/en_us/article/mg9vvn/how-our-likes-helped-trump-win) de Enero de 2017. Desde nuestra fundación hemos estado preocupados por el mal uso -intencional o no- de las ciencias y métodos cuantitativos que obtienen información de los datos -sean "big" o "small"-, desde sesgos simples, pero frecuentes, como "correlación implica causalidad", hasta las debilidades nacionales para participar en este mercado y el tipo de profesionales que producimos para esta disciplina. Este caso es de particular interés para nosotros porque viola 3 de los 5 estatutos del [Juramento Hipocrático del Modelador](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1324878), y dada la abundancia de datos, y lo sencillo de hacer predicciones espurias, asumimos como nuestro deber vigilar esta sucesión de eventos.

## Declarándole la guerra a CA
En Abril de 2017 nos enteramos que CA deseaba comenzar operaciones en México. Nos reunimos con la empresa Tasty Data (de quien queda poco más que su [cuenta de TW](https://twitter.com/tastydata) y su [sitio de Github](https://github.com/tastydata)), y nos revelaron que se asociarían con CA para trabajar en análisis de datos para marketing político. Coincidentalmente, al cabo de días, colegas de nuestra comunidad nos notificaron que estaban siendo contactados por Arielle Karro, gerente de operaciones de CA en aquel momento, para ser reclutados en el equipo de ciencia de datos de la empresa, con la pretenciosa línea de ventas "¿quieres formar parte del equipo que definirá la siguiente elección en México?".

Abiertamente le solicitamos a la comunidad y al gremio de matemáticos, físicos y actuarios que, de ser posible, no trabajaran para CA ni cedieran a los agresivos mensajes de reclutamiento de la empresa, ni a su muy atractivo y dolarizado paquete de compensaciones. También nos acercamos a nuestros aliados de [SocialTIC](https://socialtic.org/), una ONG dedicada a apoyar el infoactivismo, sobre cómo ser más efectivos en nuestra batalla contra la empresa desde su trinchera. Finalmente, conversamos con gente de El Financiero y con [Channel 4](https://www.channel4.com/news/exposed-undercover-secrets-of-donald-trump-data-firm-cambridge-analytica) de Gran Bretaña para presentarles nuestra hipótesis sobre el ecosistema de empresas y los posibles flujo de datos entre ellas en su operación en el país, y así buscar aliados en esta batalla.

## Lo inmoral de CA no es solo su mecanismo de obtención de datos
Todas las notas en los medios, y las posteriores "[disculpas](https://www.recode.net/2018/3/25/17161262/facebook-cambridge-analytica-apology-ads-newspapers-data-washington-post-new-york-times)" de Facebook se centran en la manera poco ética de recabar los datos, y aunque es, en efecto escandaloso y a ultranza condenable, lo más inmoral de esto es el resultado del modus operandi de la empresa:

1. Se recaban, limpian, y analizan datos.
2. Se produce un brief de marketing que especifica la audiencia meta, los mensajes, y los indicadores de desempeño de la campaña.
3. El brief decanta en contenido, que puede tomar forma de notas, memes y hasta fake news. El contenido pudiera no ser producido por la misma empresa que crea el brief.
4. Se crean pautas de Facebook para promocionar dicho contenido a la audiencia indicada por el brief.
5. Se recoge la data para evaluar efectividad del contenido y de la pauta. Se reinicia desde el paso 1.

Estas pautas crean [cámaras de eco](https://es.wikipedia.org/wiki/C%C3%A1mara_de_eco_(medios)) entre grupos del mismo perfil psicométrico, tal que a alguien con perfil liberal, que probablemente tiene un círculo de amigos liberales, le sea mostrado contenido que vaya de acuerdo a este perfil liberal, y lo comparta con su círculo, volviéndolo viral solo en ese microcosmos de preferencias políticas. Lo mismo sucede con alguien de perfil conservador, con los "indecisos", e incluso con los apolíticos.

Esto introduce sesgos en nuestras opiniones, haciéndonos creer que todo mundo piensa como nuestro círculo, y de este modo influir, por ejemplo, en la decisión de voto, provocando que cierto grupo "sienta" que la victoria de su candidato está asegurada, y no salga a votar, o que otro grupo sienta que necesita salir a apoyar a su propia alternativa.

Lo condenable e inmoral de esta operación está justamente en las cámaras de eco, en el aislamiento de grupos que de otra forma se podrían nutrir de las opiniones de otros, en las discusiones sin argumentos o con información falsa, y ulteriormente, en la fragmentación y la polarización de posturas políticas, tal que el "contínuo político" se discretice y tengamos numerosas facciones sin ningún tipo de coincidencias sobre las cuales se pueda construir una democracia, y en México, con instituciones débiles, un electorado apático, y una clase política cínica, el daño de esta división puede ser irreparable.

La manera de contrarrestar estos efectos a nivel individual es sencilla: 1) sé juicioso con la información que consumes, y 2) habla con personas con opiniones distintas a la tuya. Sin embargo, desde el gremio de ciencia de datos, matemáticas, estadística, física y actuaría, nuestra tarea es más grande y más importante: la de promover una ciencia bien hecha, sin sesgos ni mitos, enfocada primero en el problema, luego en la tecnología disponible para su solución, sin fetichismos tecnológicos, ni exhuberancia ni entusiasmo irracionales, y que se asuma como interventora de coherencia y veracidad en su contacto con la realidad.

## Empresas Confundidas + Hacker Schools = Muchos Datos + Poca Ciencia
La ciencia de datos, aunque [no es nueva](https://en.wikipedia.org/wiki/Timeline_of_machine_learning), es una disciplina con muchísimo auge y anunciada como "[el trabajo más sexy del s. XXI](https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century)", con salarios en México de hasta $45,000 mensuales, y en ocasiones mayor, dependiendo de la experiencia. Esto, naturalmente y por fuerzas de mercado, implica que muchos profesionistas quieran ingresar a la disciplina, y que, para responder a esa demanda, numerosas universidades y escuelas se lancen a crear programas de formación para producir a estos profesionistas. Los útimos participantes del mercado en lanzar programas para entrenar a estos perfiles son las escuelas de educación por internet y las "hacker schools", que prometen lograr un ambicioso nivel de expertise en el alumno, sin necesariamente cumplir requisitos de rigor educativo o académico.

En realidad, dichas escuelas cumplen un propósito que, por el momento, aporta cierto valor en el ecosistema de ciencia de datos, y es el de suplir talento técnico capaz de prototipar rápido, limpiar y unir bases de datos, producir visualizaciones, y, en general, realizar la labor de preparación de datos para el análisis. A medida que las empresas transicionen a culturas de decisiones basadas en evidencia, este talento será más demandado y afortunadamente, observamos que México, con 113 mil ingenieros al año, según cifras del IMCO, podrá cumplir la demanda con ayuda de estas escuelas.

El problema viene cuando las empresas ponen a este personal, que carece de entrenamiento experiencia en el proceso y método de **hacer ciencia**, a producir análisis con los cuales se tomarán decisiones estratégicas de negocio, de política pública, de salud, o macroeconómicas. Estas empresas pocas veces tienen clara su necesidad, y, requiriendo roles diferentes como analista de negocios, ingenieros de procesos, o, llanamente, programadores, deciden abonar a la confusión y a la irracionalidad abriendo posiciones de "Científico de Datos" sin que al interior la empresa esté preparada para este cambio de paradigma, y sin que el colaborador reclutado tenga experiencia en análisis riguroso que aporte a una estrategia veraz, certera, y sobre todo, buena.

### Una historia de ciencia de datos fallida
Existen numerosos casos de cómo los algoritmos, cuando se hacen sin rigor matemático ni siguiendo el método científico, y no se comienza con un problema perfectamente planteado, pueden resultar en acciones incorrectas, poco éticas, y en ocasiones, inmorales. Ejemplos típicos son los de Google, con su clasificador de imagenes [etiquetando a 2 afroamericanos como gorilas](https://www.wired.com/story/when-it-comes-to-gorillas-google-photos-remains-blind/), debido a sesgos no verificados por el ingeniero que lo desarrolló, o con su predicción de una epidemia de influenza H3N2 basado solamente en el número de búsquedas, sin tomar en cuenta contexto, epidemiología, cepa, temperaturas, etc.

Cualquier profesional de ciencias cuantitativas, y sobre todo que trabaje con datos, tiene entre sus máximas la de "el contexto es rey", y es esta máxima la que los egresados de las escuelas de capacitación frecuentemente descuidan. Esta deficiencia, y otros vicios como el de "correlación implica causalidad", viene de una definición pobre del problema, y de las limitaciones lógicas de quien lo hace. Sin embargo, no es responsabilidad de dichas escuelas formar a estos elementos en lógica y en tener una buena higiene argumentativa (aunque sería súper útil si lo fuera). La responsabilidad cae en las universidades, las cuales lamentablemente han menospreciado el rol de la filosofía en la formación profesional, y los han reemplazado por capacidades secundarias y transferibles; las mismas en las que estas escuelas modernas de entrenamiento y "hacker schools" están ganándoles terreno.

México no está exento de estos casos. Como ejemplo, durante los eventos del sismo del 19 de Septiembre, un colectivo de programadores se lanzó a crear una inteligencia artificial para detectar daño estructural con solo una fotografía. El algoritmo en particular que deseaban utilizar requiere unas decenas de miles de fotografías para ser entrenadas, o de lo contrario arrojará numerosos falsos positivos y negativos. En cristiano: se equivocará mucho. Esto es normal, todos los modelos y algoritmos usados por la ciencia de datos (llámense inteligencia artificial, aprendizaje automático, o aprendizaje estadístico) se equivocan. El problema aquí fue no contextualizar dichas equivocaciones. Si esta IA marcara una foto como "daño estructural", y no lo es realmente, las personas saldrían a los albergües y ocuparían los servicios que alguien más, cuyo hogar si sufrió daño, debería ocupar. O peor, si la IA marcara una foto como "sin daño", cuando si lo es, la vida de las personas correría peligro. Afortunadamente, estas consideraciones fueron tomadas en cuenta por miembros de dicho colectivo con más experiencia y accedieron a que el proyecto se quedara como artefacto académico, y no hacerlo público en una situación de emergencia como la que estábamos viviendo.

## El rol de la falta de talento en el próximo CA
La falta de rigor matemático e higiene argumentativa para formular la pregunta correcta, y la falta de interés genuino por su contexto son algunas de las razones por las que los algoritmos cometen errores. El caso particular de CA implica estas mismas 3 faltas. La poca higiene argumentativa puede provocar que contestemos la pregunta equivocada, por ejemplo ¿queremos que la gente salga a votar, o ganar seguidores en redes sociales? ¿Queremos mejorar el revenue en general, o solo la parte atribuíble a ingreso por operaciones?. La falta de rigor matemático puede provocar que establezcamos correlaciones espurias, como el que cierta población tenga gusto por la música clásica y los algoritmos la ubiquen en el espectro político conservador, sin considerar otras variables más influyentes o reveladoras. Finalmente, la falta de interés en el contexto deja la puerta abierta para todo tipo de acciones o consecuencias inmorales, porque se privilegió el algoritmo, y la tecnología para llevarlo a la realidad, sobre una discusión sensata y verdadera sobre las implicaciones de dicho algoritmo en todo el sistema político. Para solucionar esta deficiencia solo vemos 2 acciones: 1) que las Hacker Schools reviertan la tendencia educativa e incorporen filosofía de la ciencia en sus programas, y dejan de prometer "ciencia de datos al vapor" y "volverte experto en 2 semanas", con el respectivo riesgo financiero por el incremento en el "time to value" y 2) que las empresas realicen una autocrítica severa sobre su propensión a la exhuberancia irracional con respecto a sus iniciativas de datos, y se ubiquen en el lugar apropiado en su ciclo de madurez. De lo contrario, estaremos creando las condiciones necesarias para una burbuja, que al estallar hará que toda esta práctica se lleve a India, como sucedió con gran parte del desarrollo de software mexicano en 2006 (con resultados desastrosos, como se enteraron [4 años después](https://www.gadgetsnow.com/jobs/95-engineers-in-india-unfit-for-software-development-jobs-claims-report/articleshow/58278224.cms)). Estas mismas condiciones son las que pueden provocar el surgimiento de otro CA en el horizonte, presto para efectuar análisis incorrectos, correlaciones espurias, y acciones inmorales.

